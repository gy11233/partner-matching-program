
# 伙伴匹配系统面向简历

## 相似度匹配部分改进
- 首先介绍相似度这个字段是怎么存的 => 用户定义标签，存成一个json串["标签1", "标签2"]
80w数据测试情况
改进之前 2.58s
经过测试，基本上大部分时间都是用来查询数据库所有信息 总共需要 2553ms
1. 用插入排序 只维护top n用户 改了之后变成2.55s
2. 不从数据库中加载所有的用户，只随机加载部分用户
    - 找部分用户的top n
    - 如果top n中相似度最小的得分达到阈值 就可以直接返回
    - 否则继续加载用户
    - 数据库查询阶段只用了634ms（单次查询就可以达到阈值要求的情况
      最终查询优化：时间964ms

## 缓存预热
- 分页查询用户，涉及到计算两个用户间距离的操作，时间长，访问一次之后会放到缓存里，再查询会快很多，主要解决第一次查询慢的问题
- recommend是用户首页，并且加载变化不是很大，可以考虑缓存预热
- 预热是按照每个用户存储对应的推荐用户，只存储20个
- 用户多了之后redis压力大，只存储重点用户
- 系统真正有人使用之后选取活跃度高（用户打卡统计）的用户进行预热
- 支持滑动加载redis stringList实现，这样可能出现一个问题，出现并发请求缓存多次写入同一组数据  ==> 用分布式锁来解决，对查询数据库到写入缓存加锁

## 布隆过滤器解决缓存穿透

**缓存穿透：**
> 客户端请求的数据在缓存中和数据库中都不存在，都会请求到数据库
场景：
- 用户登录，用户不存在如果一直请求会导致数据库压力过大

解决方案：
- 缓存空对象：数据库不存在之后写入空对象到缓存中，
- 布隆过滤器：客户端和redis之间存在一个布隆过滤器，用于判断请求的数据是否存在✅
- 主动防御：
    - 增加id的复杂度，不让敌手轻易伪造
    - **做好热点参数的限流**
    - 加强用户权限校验

步骤：
1. 引入pom依赖 redisson,配置redisson.config
2. 配置布隆过滤器
   - 在布隆过滤器增加元素之前，首先需要初始化布隆过滤器的空间，
   - 布隆过滤器提供了两个参数，分别是预计加入元素的大小n，运行的错误率f。
   - 布隆过滤器中有算法根据这两个参数会计算出二进制数组的大小，以及无偏hash函数的个数k。 
   - 它们之间的关系比较简单： •错误率越低，位数组越长，控件占用较大 •错误率越低，无偏hash函数越多，计算耗时较长
3. 配置aop切面 在直接通过id获取用户和队伍的接口配置布隆过滤器
   - @Aspect 注解 + @Before和@AfterReturning注解来配置
4. 在新增队伍和用户的模块同时加入布隆过滤器
5. 配置定时任务，定时更新布隆过滤器（分布式锁 只有一个服务器进行更新） 三天3点更新
   - bloom在删除和重新充值时（即定时任务的时候） ==数据量比较大的时候会比较耗时==
   - job开始删除、重新充值bloom filter里的值时使用redission自续约锁上锁；
   - 之后有两种实现思路：
     1. 每次判断用户请求进来和bloom filter里的值进行比对前先去拿一下redis锁；
        - 如果此时已经锁住，放过请求；
        - 如果拿不到锁，走正常redis bloom filter的拦截逻辑；
        - 问题：比较耗时，尤其是正常情况下影响并发
     2. 直接先新定义一个布隆过滤器，添加好数据之后 通过lua脚本 删除旧的布隆过滤器 新的布隆过滤器换名字
     



## 引入ES实现位置信息存储和查找
需求分析：用户可以根据位置信息查找附近的用户
参考：
https://cloud.tencent.com/developer/article/1442673
https://blog.csdn.net/qq_26545503/article/details/106461821

### 技术对比
#### 基本知识
世界上标识一个位置，通用的做法就使用经、纬度。经度的范围在 (-180, 180]，纬度的范围 在(-90, 90]

**GeoHash**
- 定位一个位置最好的办法就是用经、纬度标识，但经、纬度它是二维的，在进行位置计算的时候还是很麻烦
- 如果能通过某种方法将二维的经、纬度数据转换成一维的数据，那么比较起来就要容易的多，因此GeoHash算法应运而生
- GeoHash算法将二维的经、纬度转换成一个字符串
    - GeoHash字符串越长，表示的位置越精确，字符串长度越长代表在距离上的误差越小
    - 字符串越相似表示距离越相近，字符串前缀匹配越多的距离越近
    - 具体原理：https://cloud.tencent.com/developer/article/1442636
    - 把地球划分成小格子，用二分来进行划分，然后用二进制来表示
- 存在问题：两个点距离近但是在不同划分的格子里，反而距离远
    - 一般我们在业务中使用geohash的时候，一般不会仅仅使用一块区域的geohash，而是顺带将该区域周遭的八个区域也带上一起查询；在查询完后完毕出来结果后，还需要进行结果进行距离运算，然后按照距离进行排序

#### mysql
1. 不用geohash算法：存储经纬度，先查询出正方形区域，之后计算区域的点到用户的距离，找出r半径内的用户
    - 简单
    - 需要大量计算
2. MySQL + GeoHash：根据用户经、纬度属性计算出相应的GeoHash字符串，geohash字符串保存到MySQL数据库里，然后通过MySQL的like去模糊匹配geohash前缀

#### Redis + geohash
- 读多写少的场景，可以用redis进行加速
- 用到了有序队列zset以及geohash编码的数据结构
- 原理：https://cloud.tencent.com/developer/article/1526950
    - Redis内部使用有序集合(zset)保存位置对象，有序集合中每个元素都是一个带位置的对象，元素的score值为其经纬度对应的52位的geohash值
    - 查找附近的人要查找9宫格，每个格子里的对象在跳表里是挨着的，不同的格子不一定挨着

#### MongoDB+2d索引
- 两种地理空间索引 2dsphere 和 2d，可以看成是存储的geohash
    - 2dsphere 索引仅支持球形表面的几何形状查询。
    - 2d 索引支持平面几何形状和一些球形查询。虽然2d 索引支持某些球形查询，但 2d 索引对这些球形查询时，可能会出错。所以球形查询尽量选择 2dsphere索引。
    - 都用geoJSON的标准格式来描述
    - https://www.cnblogs.com/sheseido/p/9807779.html
- 请求频繁可能操作超时连接问题 mongodb会随数据量的增加在地理位置查询时性能会急剧下降

#### ElasticSearch
- 多条件搜索强
- geopoint Elasticsearch的默认等级是9，也就是精准到4.8米左右
- 具体实现的发展过程：https://www.cnblogs.com/vivotech/p/16405981.html
    - es2.0版本：经纬度矩形初始筛查 之后计算两点距离精筛查， 缺点：筛查的记录太多了
    - es2.2版本：基于四叉树(Quadtree)的地理位置查询(Lucene 5.3版本实现)
        - morton编码：将二维坐标转换成一维坐标，和geohash类似 TODO:只用实现前缀匹配
        - 划分所查找的矩形区 => 用Quadtree进行矩形区域初筛 => 经纬度计算距离精筛
    - es5.0版本：**bkd-tree**独立索引 https://blog.csdn.net/weixin_43265851/article/details/119246595
        - 将N维点集合形成的矩形空间(southWest,northEast)递归分割成更小的矩形空间。跟常见的kd-tree不同，当分割到网格区域里面坐标点的数量小于一定数量(比如1024)就停止了 => 来保证划分成差不多大的矩形区域
        - 生成待查询矩形区域 => 查询bkd-tree索引叶子结点的位置关系 => 计算两点间的距离

#### postgis
- 一个空间数据库
-
#### 总结
实现方法：
- 不用任何数据结构 mysql
- 用geohash算法 mysql redis  -> 先计算网格登记，再多计算周围的8个区域，之后计算距离精筛
- 用bkd-tree算法 es -> 生成待查询矩形区域 => 查询bkd-tree索引叶子结点的位置关系 => 计算两点间的距离
- 用2d索引 mongodb -> R树



